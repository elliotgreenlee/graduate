{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14176608\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(appName=\"Pi\")\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"TweetClassification\").getOrCreate()\n",
    "df = spark.read.csv()\n",
    "df.show() # show the first 20 lines\n",
    "df.count() # count total records\n",
    "df.printSchema() # show columns and associated type\n",
    "df.select('column').show(n=5, truncate=False) # show first five items\n",
    "df.where(df['column'] == \"alkjdfhalskjdfh\").show() # show a specific tweet \n",
    "\n",
    "df = df.withColumn(\"column\", df['column'].cast('float')) # add a new column, but same name so overwrite\n",
    "\n",
    "filtr = df['column'].isNotNull()\n",
    "df = df.where(filtr) # filter operation\n",
    "\n",
    "df = df.select('column1', 'column2') # create a new df with the specific columns\n",
    "df = df.drop() # drop certain columns\n",
    "df = df.join() # join...two tables? idk\n",
    "\n",
    "# user defined function\n",
    "udf_function = udf(python_function, DataType())  # output datatype for the new column\n",
    "df = df.withColumn(\"output_col\", udf_function('input_col'))\n",
    "\n",
    "df.count() # counts total records\n",
    "df.describe() #summary statistics \n",
    "df.agg({'column': 'statistic'}) # statisitc is like min, max, etc.\n",
    "df.groupBy() # idk\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"column1\", outputCol=\"tokens\") # ml word tokenization\n",
    "NGram() # multiple gram tokens\n",
    "stopwards = set(stopwords.words('english'))\n",
    "stem =  SnowballsStemmer('english') # remove end of the word running -> run\n",
    "hashingTF = HashingTF(inputCol='column1', ouputCol='term_frezuency') # term frequency\n",
    "idf = IDF(inputCol=('column1'), outputCol='_frequency') # other frequency\n",
    "\n",
    "# train test split function exists\n",
    "test,train = \n",
    "\n",
    "nb = NaiveBayes(featuresCol='', labelCol='', predictionCol='', probabilityCol='confidence', rawPredictionCol='')\n",
    "nbModel = nb.fit(train)\n",
    "test = nbModel.transform(test)\n",
    "test.show()\n",
    "\n",
    "total = test.count()\n",
    "correct = df.where(guess == truth)\n",
    "correct/total # accuracy\n",
    "\n",
    "spark.stop() # close it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
